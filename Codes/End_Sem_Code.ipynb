{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2, glob, os, warnings\n",
    "from cv2 import blur as box_filter\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dark Channel\n",
    "Paper Reference: <b>Single Image Haze Removal Using Dark Channel Prior</b> by Kaiming He, Jian Sun et. al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(img, title, cmap=''):\n",
    "    \"\"\"\n",
    "    Draw plot of a image with title passed as parameters \n",
    "    \"\"\"\n",
    "    if (len(cmap) != 0):\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_value_patch_channel(img, rows, columns, patch_size):\n",
    "    \"\"\"\n",
    "    Get channelwise min value for each pixel\n",
    "    \"\"\"\n",
    "    min_channel, border = np.zeros((rows, columns)), patch_size // 2\n",
    "    for row in range(rows):\n",
    "        for col in range(columns):\n",
    "            min_channel[row - border][col - border] = np.min(img[row, col, :])\n",
    "    return min_channel\n",
    "\n",
    "\n",
    "def get_min_value_patch_whole(img, channel, rows, columns, patch_size):\n",
    "    \"\"\"\n",
    "    Get dark channel image of a given image\n",
    "    \"\"\"\n",
    "    dark_channel, border = np.zeros((img.shape[0], img.shape[1])), patch_size // 2\n",
    "    \n",
    "    # Applying Min Filter\n",
    "    for row in range(border, rows - border):\n",
    "        for col in range(border, columns - border):\n",
    "            dark_channel[row - border][col - border] = np.min(\n",
    "                channel[row - border:row + border, col - border:col + border])\n",
    "    return dark_channel\n",
    "\n",
    "\n",
    "def calculate_dark_channel_image(img, patch_size):\n",
    "    \"\"\"\n",
    "    Calls above function after padding to generate dark channel image of a hazy image\n",
    "    given as parameter.\n",
    "    \"\"\"\n",
    "    dark_channel, border = np.zeros((img.shape[0], img.shape[1])), patch_size // 2\n",
    "    white_pixel_value = [255, 255, 255]\n",
    "    \n",
    "    # padding rows and columns equal to half patch size to be used by Min Filter later \n",
    "    img = cv2.copyMakeBorder(img, border, border, border, border, cv2.BORDER_CONSTANT, value = white_pixel_value)\n",
    "    no_rows, no_cols = img.shape[0], img.shape[1]\n",
    "    \n",
    "    # channel-wise min value\n",
    "    min_channel = get_min_value_patch_channel(img, no_rows, no_cols, patch_size)\n",
    "    \n",
    "    # min pixel value in patch applied on each pixel (Min filtering)\n",
    "    dark_channel = get_min_value_patch_whole(dark_channel, min_channel, no_rows, no_cols, patch_size)\n",
    "    return dark_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atmospheric light - A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atmospheric_light_A(h_img, dark_img):\n",
    "    \"\"\"\n",
    "    Calculates Global Atmospheric light in hazy image using its dark channel image   \n",
    "    \"\"\"\n",
    "    print('Image size:', dark_img.shape)\n",
    "    img = h_img.copy()\n",
    "    total_pixels = dark_img.size\n",
    "    print('# pixels:', total_pixels)\n",
    "    bright_pixels_count = total_pixels // 1000  # 0.1% from paper\n",
    "    print('# bright pixels:', bright_pixels_count)\n",
    "    \n",
    "    # getting indices of brightest pixels in the deep-channel image and Indices sorted based on \n",
    "    # corresponding pixel values in Descending order\n",
    "    sorted_indices_of_bright_pixels = np.argsort(dark_img, axis=None)[::-1]\n",
    "    \n",
    "    # top 0.1% =3296\n",
    "    sorted_indices_of_bright_pixels = np.unravel_index(sorted_indices_of_bright_pixels[0:bright_pixels_count], dark_img.shape)\n",
    "    print('Top 0.1% pixel indices:', sorted_indices_of_bright_pixels)\n",
    "    \n",
    "    # identify pixels in hazy image at the same indices as that of top 0.1% brightest pixels in its dark channel image  \n",
    "    bright_pixels = img[sorted_indices_of_bright_pixels]  \n",
    "    \n",
    "    # first find intensities of selected bright pixels in the hazy image, \n",
    "    # and then choose the pixel with maximum intensity among them as global atmospheric light i.e. A\n",
    "    A = bright_pixels[np.argmax(np.average(bright_pixels, axis=1))]\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Filter\n",
    "Paper Reference: <b>Guided Image Filtering</b> by Kaiming He, Jian Sun et. al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(img, unrefined, r):\n",
    "    \"\"\"\n",
    "    Calculates and returns hazy image and unrefined transmission map after box filtering them individually \n",
    "    and then filtering their product  \n",
    "    \"\"\"\n",
    "    return box_filter(img, (r, r)), box_filter(unrefined, (r, r)), box_filter(img * unrefined, (r, r))\n",
    "\n",
    "def guided_filter(h_img, unrefined_transmission_map, r, e):\n",
    "    \"\"\"\n",
    "    This fuction takes unrefined transmission map as input image and applies guided filter on it \n",
    "    to refine it using the hazy image as guidance image\n",
    "    \"\"\"\n",
    "    filtered_guidance_mean, filtered_transmission_mean, filtered_guided_transmission = filtering(h_img, unrefined_transmission_map, r)\n",
    "\n",
    "    # calculating window parameters a and b\n",
    "    a = filtered_guided_transmission - filtered_guidance_mean * filtered_transmission_mean\n",
    "    filtered_guidance_variance = box_filter(h_img * h_img, (r, r)) - (filtered_guidance_mean * filtered_guidance_mean)\n",
    "    a = a / (filtered_guidance_variance + e)\n",
    "    b = filtered_transmission_mean - a * filtered_guidance_mean\n",
    "\n",
    "    # deriving a_bar and b_bar using box filter on a and b respectively\n",
    "    a_bar = box_filter(a, (r, r))\n",
    "    b_bar = box_filter(b, (r, r))\n",
    "    q = a_bar * h_img + b_bar  # q is the refined transmission map\n",
    "    return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dehazed Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dehazed_image(h_img, transmissionMap, A, t0):\n",
    "    \"\"\"\n",
    "    This function calculates Dehazed image by fitting values of A and transmission map\n",
    "    in Haze imaging model equation\n",
    "    \"\"\"\n",
    "    temp = np.copy(transmissionMap)\n",
    "    temp[temp < t0] = t0  # clipping the values --> max(t1, t0)\n",
    "    dehazed_img = np.zeros((h_img.shape))  # reconstruction img from formula\n",
    "    channels = 3\n",
    "    \n",
    "    # Applying Haze imaging model channelwise\n",
    "    for ch in range(channels):\n",
    "        dehazed_img[:, :, ch] = ((h_img[:, :, ch] - A[ch]) / temp) + A[ch]\n",
    "    return dehazed_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplest Color Balanced Image\n",
    "Paper Reference: <b>Simplest Color Balance</b> by Nicolas Limare et.al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_balance(h_img, s):\n",
    "    \"\"\"\n",
    "    Applying simple color balancing technique to refine contrast of image. The dehazed image obtained\n",
    "    using above functions looks dim due to haze component removal. This function increases image sharpness\n",
    "    \"\"\"\n",
    "    color_balanced_img = np.copy(h_img)\n",
    "    max_intensity_levels, channels, V_min, V_max = 256, 3, 0, 255\n",
    "    histogram = np.zeros((max_intensity_levels, 1))\n",
    "    total_pixels = h_img.shape[0] * h_img.shape[1]\n",
    "    for i in range(channels):\n",
    "        color_channel = h_img[:, :, i]\n",
    "        for p in range(max_intensity_levels):\n",
    "            histogram[p] = np.sum((color_channel == p))\n",
    "        for p in range(max_intensity_levels):\n",
    "            histogram[p] = histogram[p - 1] + histogram[p]\n",
    "\n",
    "        while (V_min < 255 and histogram[V_min] <= total_pixels * s):\n",
    "            V_min += 1\n",
    "        while (V_max > 0 and histogram[V_max] > total_pixels * (1 - s)):\n",
    "            V_max -= 1\n",
    "        color_channel[color_channel < V_min] = V_min\n",
    "        color_channel[color_channel > V_max] = V_max\n",
    "        color_balanced_img[:, :, i] = cv2.normalize(color_channel, color_channel.copy(), 0, 255, cv2.NORM_MINMAX)\n",
    "    return color_balanced_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_dehazed_image(hazy_img, patch_size):\n",
    "    # get dark channel img of the given hazy image \n",
    "    dark_channel_img = calculate_dark_channel_image(hazy_img, patch_size).astype('uint8')\n",
    "    \n",
    "    # get global atmospheric light \n",
    "    A = atmospheric_light_A(hazy_img, dark_channel_img)\n",
    "    \n",
    "    # get unrefined transmission map\n",
    "    OMEGA = 0.85  # min haze factor\n",
    "    unrefined_transmission_map = 1 - (OMEGA * calculate_dark_channel_image(hazy_img / A, patch_size))\n",
    "    plot(unrefined_transmission_map, 'UnRefined Transmission map', cmap='gray')\n",
    "    \n",
    "    # apply guided filter on the unrefined transmission map\n",
    "    radius, epsilon = 30, 0.0001\n",
    "    gray_scale_hazy_img = cv2.cvtColor(hazy_img, cv2.COLOR_BGR2GRAY) / 255\n",
    "    transmission_map = guided_filter(gray_scale_hazy_img, unrefined_transmission_map, radius, epsilon)\n",
    "    plot(transmission_map, 'Refined Transmission Map image', cmap='gray')\n",
    "    \n",
    "    # Haze imaging model\n",
    "    haz_img = hazy_img.astype(\"double\")\n",
    "    dehaz_image = Dehazed_image(haz_img, transmission_map, A, 0.1)\n",
    "    dehaz_image = ((dehaz_image - np.min(dehaz_image)) / (np.max(dehaz_image) - np.min(dehaz_image))) * 255\n",
    "    \n",
    "    # Apply color balancing in the dehazed image obtained\n",
    "    s = 0.005\n",
    "    finalImage = color_balance(np.uint8(dehaz_image), s)\n",
    "    \n",
    "    return dehaz_image, finalImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(gr_truth_img, hazy_img, dehaz_image, finalImage):\n",
    "    plot(gr_truth_img, 'Original image')\n",
    "    plot(hazy_img, 'Hazy image')\n",
    "    plot((np.uint8(dehaz_image)), 'Dehazed image')\n",
    "    plot((np.uint8(finalImage)), 'Color balanced image')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling above functions stepwise for haze removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_path = r\".\\Dataset\\I-HAZE\\I-HAZY NTIRE 2018\\GT/02_indoor_GT.jpg\"\n",
    "# hazy_img_path = r\".\\Dataset\\I-HAZE\\I-HAZY NTIRE 2018\\hazy/02_indoor_hazy.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = r\".\\Dataset\\O-HAZE\\O-HAZY NTIRE 2018\\GT/41_outdoor_GT.jpg\"\n",
    "hazy_img_path = r\".\\Dataset\\O-HAZE\\O-HAZY NTIRE 2018\\hazy/41_outdoor_hazy.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_truth_img = cv2.imread(gt_path)\n",
    "gr_truth_img = cv2.resize(gr_truth_img, (0, 0), fx=0.5, fy=0.5)\n",
    "hazy_img = cv2.imread(hazy_img_path)\n",
    "hazy_img = cv2.resize(hazy_img, (0, 0), fx=0.5, fy=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 30\n",
    "dehaz_image, finalImage = get_final_dehazed_image(hazy_img, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_images(gr_truth_img, hazy_img, dehaz_image, finalImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
